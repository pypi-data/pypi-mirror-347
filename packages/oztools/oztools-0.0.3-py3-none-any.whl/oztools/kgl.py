"""Command line utilities for kaggle competitions"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/03_kgl.ipynb.

# %% auto 0
__all__ = ['setup_comp', 'disp_comp', 'get_competitions', 'kgl_list', 'maybe_int', 'get_competition', 'kgl_new',
           'create_lib_dataset']

# %% ../nbs/api/03_kgl.ipynb 3
from fastcore.all import *
from fastkaggle import *
import itertools as it

from .core import *
from .nbd import *

import os,json,subprocess, shutil
import re

# %% ../nbs/api/03_kgl.ipynb 7
def setup_comp(competition, install=''):
    "Get a path to data for `competition`, downloading it if needed"
    if iskaggle:
        if install:
            os.system(f'pip install -Uqq {install}')
        return Path('../input')/competition
    else:
        path = Path('./var')/competition
        api = import_kaggle()
        if not path.exists():
            import zipfile
            api.competition_download_cli(str(competition), path='./var')
            zipfile.ZipFile(f'./var/{competition}.zip').extractall(path)
        return path

# %% ../nbs/api/03_kgl.ipynb 11
def disp_comp(comp):
    slug = comp.url.split("/")[-1]
    return f"{pad(slug[:40],40)} {comp.title[:40]}"

# %% ../nbs/api/03_kgl.ipynb 14
def get_competitions():
    api = import_kaggle()
    comps = api.competitions_list()
    
    joinedkey = attrkey("user_has_entered")
    comps.sort(key=joinedkey)
    active, entered = (list(y) for x,y in it.groupby(comps, joinedkey))
    return active, entered

# %% ../nbs/api/03_kgl.ipynb 16
@call_parse
def kgl_list():
    "List kaggle competitions"

    active, entered = get_competitions()

    return '\n'.join(("Joined:", *str_enumerate(map(disp_comp, entered), 1),
                      "Active:", *str_enumerate(map(disp_comp, active), 1+len(entered))))

# %% ../nbs/api/03_kgl.ipynb 18
def maybe_int(x: str):
    try:
        return int(x)
    except ValueError:
        return x

# %% ../nbs/api/03_kgl.ipynb 22
def get_competition(n: str):
    active, entered = get_competitions()
    comps = entered + active

    try:
        try: return comps[int(n)-1]
        except ValueError: return L(comps).filter(lambda x: n in x.url.split("/")[-1])[0]
    except IndexError:
        warn("Couldn't find competition")
        return

# %% ../nbs/api/03_kgl.ipynb 23
@call_parse
def kgl_new(n: str, # competition id or name
            save_to: str # project name to use locally and for github
            ):
    "Setup nbdev environment for a kaggle competition"
    comp = get_competition(n)
    if not comp:
        return

    save_to = "kaggle_" + save_to
    
    print(f'Loading competition "{comp.title}" into "{save_to}"')
    nbd_new_fn(save_to, f'Code for [{comp.title}]({comp.url}) Kaggle competition')

# %% ../nbs/api/03_kgl.ipynb 25
def create_lib_dataset(ds_name,
                       lib_source,
                       lib_path, # Local path to dl/create dataset
                       username, # You username
                       clear_after=False # Delete local copies after sync with kaggle?
                       ):
    '''For each library, create or update a kaggle dataset with the latest version'''    
    retain = ["dataset-metadata.json"]

    lib = lib_source
    title = f"library-{ds_name}"
    local_path = lib_path/title
    print(f"{lib} | Processing as {title} at {local_path}")
    if Path(local_path).exists(): shutil.rmtree(local_path)

    print(f"{lib} | Downloading or Creating Dataset")
    try: get_dataset(local_path,f"{username}/{title}",force=True)
    except Exception as ex:
        if '404' or '403' in str(ex): mk_dataset(local_path,title,force=True)
        else: raise ex
        
    print(f"{lib} | Checking dataset version against pip")
    ver_local_orig = get_local_ds_ver(lib_path,lib)

    for item in local_path.ls():
        if item.name not in retain: 
            if item.is_dir(): shutil.rmtree(item)
            else: item.unlink()
    get_pip_library(local_path,lib)
    ver_local_new = get_local_ds_ver(lib_path,lib)
    if (ver_local_new != ver_local_orig) or (ver_local_new==None and ver_local_orig==None): 
        print(f"{lib} | Updating {lib} in Kaggle from {ver_local_orig} to {ver_local_new}")
        
        push_dataset(local_path,ifnone (ver_local_new, "Version Unknown"))
    else: print(f"{lib} | Kaggle dataset already up to date {ver_local_orig} to {ver_local_new}")
    if clear_after: shutil.rmtree(local_path)
    print(f"{lib} | Complete")
