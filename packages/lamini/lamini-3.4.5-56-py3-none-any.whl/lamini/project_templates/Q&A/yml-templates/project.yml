Lamini:
  api_key:
    value: <your_api_key>
    description: lamini api key
  base_url:
    value: https://app.lamini.ai
    description: lamini base url
  base_url_inf:
    value: https://api.lamini.ai/inf
    description: lamini base url for inference

Project:
  project_name:
    value: initial_template
    description:
  description:
    value: project_init
    description:
  topic:
    value: topic_placeholder
    description: topic of the project
document_metadata:
  product:
    value: "LLM Training and Generalization Research Paper"
    description:
  keywords:
    value:
    - "LLM"
    - "randomization tests"
    - "regularization tests"
    - "factual recall"
    - "memory tuning"
    description:


  title:
    value: "Exploring Effective Capacity in LLMs: Randomization and Regularization Experiments"
    description:
  description:
    value: |
      This research paper investigates the effective capacity and generalization ability of large language models (LLMs) through a series of experiments. It presents analyses based on randomization tests and regularization tests, comparing training on true data versus randomized labels. The study evaluates models such as Llama 3 and Mistral v2 using benchmarks like TruthfulQA and MMLU, examining how training dynamics—including memory tuning—affect factual recall and potential hallucinations. The findings challenge conventional assumptions about overfitting and provide new insights into LLM training methodologies.
    description:
