[transcription]
speech_service = groq
groq_model = whisper-large-v3-turbo
groq_chunk_target_mb = 18
groq_chunk_overlap = 0.5

[api]
groq_model_llm = llama-3.3-70b-versatile
