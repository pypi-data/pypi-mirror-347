{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c6f42d",
   "metadata": {},
   "source": [
    "# Cell Classification with AIDO.Cell\n",
    "\n",
    "Here, we do cell type classification from the AIDO.Cell paper using 3 datasets.\n",
    "- [Zheng68K et al. 2017](https://www.nature.com/articles/ncomms14049)\n",
    "- [Segerstolpe et al. 2016](https://www.cell.com/cell-metabolism/fulltext/S1550-4131(16)30436-3)\n",
    "- [scTab et al. 2024](https://www.nature.com/articles/s41467-024-51059-5)\n",
    "\n",
    "Both of Zheng68K and Segerstolpe are preprocessed and available to download from the [GenBio AI HuggingFace](https://huggingface.co/datasets/genbio-ai/cell-downstream-tasks/tree/main).\n",
    "\n",
    "As for scTab dataset, because of its large size, we are using TileDB to load the data by chunks during training and testing. To run experiments with scTab, please download the data files from the official [scTab repo](https://github.com/theislab/scTab) and then convert the `.parquet` data files into TileDB format with this [script](./sctab_conversion.py). (Note: This conversion could take a few hours.) \n",
    "\n",
    "We also provided a minimal version of scTab in TileDB format with a subset of ~32k observations in each split (train, val, test) as an example. This is available for downloading at [here](https://huggingface.co/datasets/genbio-ai/cell-downstream-tasks/blob/main/sctab/soma-exp-scTab-minimal.tar.gz). When you have a tileDB data folder ready, simply add the data root path (either local or in docker workspace) to `config.data.init_args.path` (see [sctab_classification.yaml](./sctab_classification.yaml) as example). The train/validation/test split subfolders should be automatically ready under the root path after the conversion. \n",
    "\n",
    "For installation, see the quickstart tutorial.\n",
    "\n",
    "__Requirements__:\n",
    "- A100 GPU or equivalent\n",
    "- [ModelGenerator](https://genbio-ai.github.io/ModelGenerator/) installed\n",
    "- [HuggingFace CLI](https://huggingface.co/docs/huggingface_hub/en/guides/cli) installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ee3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download genbio-ai/cell-downstream-tasks \\\n",
    "  --repo-type dataset \\\n",
    "  --local-dir data/genbio-ai/cell-downstream-tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e5555",
   "metadata": {},
   "source": [
    "## ModelGenerator\n",
    "\n",
    "Using large models like AIDO.Cell can be a headache due to their size.\n",
    "To make it easier to work with large models, we developed [ModelGenerator](https://genbio-ai.github.io/ModelGenerator/), a research framework for cross-disciplinary teams in ML & Bio.\n",
    "ModelGenerator is designed to automatically take advantage of available of distributed training/inference workflows to scale with available hardware.\n",
    "It also provides reproducible configs for every training run, and a simple CLI to run training and inference.\n",
    "\n",
    "In this example we run cell type classification with AIDO.Cell using the ModelGenerator CLI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf4e46",
   "metadata": {},
   "source": [
    "### Data Alignment\n",
    "\n",
    "Normally the dataset must be aligned to AIDO.Cell's pretraining gene set. An example is below.\n",
    "\n",
    "Here, the Zheng and Stegerstolpe datasets are pre-aligned, and this is just for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import cell_utils\n",
    "\n",
    "# my_data = sc.read_hyad('my_data.h5ad')\n",
    "# adata_aligned = cell_utils.align_adata(my_data)\n",
    "# adata_aligned.write_h5ad('my_data_aligned.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d10cda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export timestamp for linking train and test runs\n",
    "import os\n",
    "import time\n",
    "timestamp = time.time()\n",
    "os.environ[\"TIMESTAMP\"] = str(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e95dc",
   "metadata": {},
   "source": [
    "### Finetune AIDO.Cell on Zheng68K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ec0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mgen fit --config cell_type_classification.yaml \\\n",
    "    --model.backbone aido_cell_3m \\\n",
    "    --model.adapter LinearMaxPoolAdapter \\\n",
    "    --data.path data/genbio-ai/cell-downstream-tasks/zheng \\\n",
    "    --trainer.logger lightning.pytorch.loggers.WandbLogger \\\n",
    "    --trainer.logger.version zheng_cell_type_classification_$TIMESTAMP \\\n",
    "    --trainer.val_check_interval 100 \\\n",
    "    --trainer.limit_val_batches 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0ebc",
   "metadata": {},
   "source": [
    "### Test the Best Val F1 Checkpoint on the Zheng68K test split\n",
    "\n",
    "To test, just use `mgen test` with the same command, and point to the checkpoint path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mgen test --config cell_type_classification.yaml \\\n",
    "    --model.backbone aido_cell_3m \\\n",
    "    --model.adapter LinearMaxPoolAdapter \\\n",
    "    --data.path data/genbio-ai/cell-downstream-tasks/zheng \\\n",
    "    --trainer.default_root_dir logs \\\n",
    "    --trainer.callbacks.dirpath logs/zheng_cell_type_classification/ckpts \\\n",
    "    --ckpt_path lightning_logs/cell_type_classification_$TIMESTAMP/checkpoints/best_val_f1*.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff29961c",
   "metadata": {},
   "source": [
    "### Fit and Test on Segerstolpe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mgen fit --config cell_type_classification.yaml \\\n",
    "    --model.backbone aido_cell_3m \\\n",
    "    --model.adapter LinearMaxPoolAdapter \\\n",
    "    --data.path data/genbio-ai/cell-downstream-tasks/Stegerstolpe \\\n",
    "    --trainer.logger lightning.pytorch.loggers.WandbLogger \\\n",
    "    --trainer.logger.version stegerstolpe_cell_type_classification_$TIMESTAMP \\\n",
    "    --trainer.val_check_interval 100 \\\n",
    "    --trainer.limit_val_batches 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mgen test --config cell_type_classification.yaml \\\n",
    "    --model.backbone aido_cell_3m \\\n",
    "    --model.adapter LinearMaxPoolAdapter \\\n",
    "    --data.path data/genbio-ai/cell-downstream-tasks/Stegerstolpe \\\n",
    "    --ckpt_path lightning_logs/stegerstolpe_cell_type_classification_$TIMESTAMP/checkpoints/best_val_f1*.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bff529",
   "metadata": {},
   "source": [
    "### Finetune AIDO.Cell on scTab dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de507d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mgen fit --config sctab_classification.yaml \\\n",
    "    --model.backbone aido_cell_3m \\\n",
    "    --model.adapter LinearMaxPoolAdapter \\\n",
    "    --data.path TODO \\\n",
    "    --trainer.logger lightning.pytorch.loggers.WandbLogger \\\n",
    "    --trainer.logger.version sctab_cell_type_classification_$TIMESTAMP \\\n",
    "    --trainer.val_check_interval 100 \\\n",
    "    --trainer.limit_val_batches 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
