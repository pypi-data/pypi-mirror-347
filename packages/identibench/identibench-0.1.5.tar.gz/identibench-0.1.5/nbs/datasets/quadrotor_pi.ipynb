{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadrotor PI Dataset\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.quad_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nonlinear_benchmarks.utilities import get_tmp_benchmark_directory\n",
    "import identibench.benchmark as idb\n",
    "import identibench.metrics\n",
    "from pathlib import Path\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gdown\n",
    "import bagpy\n",
    "import glob\n",
    "import scipy\n",
    "import shutil\n",
    "from scipy.signal import butter, lfilter, lfilter_zi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "fnames_test = ['ovalz_10',\n",
    "                'ovalz_4',\n",
    "                '8z_5',\n",
    "                '8z_6',\n",
    "                'line8z_4',\n",
    "                'wz_12',\n",
    "                'v_8',\n",
    "                'vT_5']\n",
    "\n",
    "fnames_valid = ['oval_5',\n",
    "                'linez_4',\n",
    "                '8_5',\n",
    "                '8_7',\n",
    "                'w_12'\n",
    "                'vz_7',\n",
    "                'v_8']\n",
    "\n",
    "def get_parent_dir(f_name: str # name of the flight\n",
    "                  ):\n",
    "    if f_name in fnames_valid:\n",
    "        return 'valid'\n",
    "    elif f_name in fnames_test:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def parseBag(topic, path):\n",
    "  bag = bagpy.bagreader(path, verbose=False)\n",
    "  return pd.read_csv(bag.message_by_topic(topic))\n",
    "\n",
    "def shift(arr):\n",
    "  if len(arr.shape) == 1:\n",
    "    arr = arr.reshape((len(arr), 1))\n",
    "  return np.vstack((np.nan * np.ones(shape=(1, arr.shape[1])), arr[:-1]))\n",
    "\n",
    "def shiftFilteredSpline(sampled_data, step):\n",
    "  for k in sampled_data.keys():\n",
    "    if \"filt\" in k:\n",
    "      sampled_data[k] = sampled_data[k][step:]\n",
    "    else:\n",
    "      sampled_data[k] = sampled_data[k][:-step]\n",
    "\n",
    "def differentiate(arr, dt):\n",
    "  a_dot = (arr - shift(arr)) / dt\n",
    "  a_dot[0, :] = np.zeros((a_dot.shape[1]))\n",
    "  return a_dot\n",
    "\n",
    "def differentiateFivePointStencil(arr, dt):\n",
    "  a_dot = [\n",
    "    [np.zeros((arr.shape[1]))],\n",
    "    [(arr[2] - arr[1]) / dt[1]]\n",
    "  ]\n",
    "  for i in range(2, len(arr) - 2):\n",
    "    a_dot.append([(- arr[i + 2] + 8 * arr[i + 1] - 8 * arr[i - 1] + arr[i - 2]) * (1. / (12 * dt[i]))])\n",
    "  a_dot.append([(arr[-2] - arr[-3]) / dt[-2]])\n",
    "  a_dot.append([(arr[-1] - arr[-2]) / dt[-1]])\n",
    "  return np.concatenate(a_dot, axis=0)\n",
    "\n",
    "def dropNoise(arr, t, dt):\n",
    "  drop_indeces = []\n",
    "  for i in range(1, len(arr)):\n",
    "    if np.any(abs(arr[i]) - abs(sum(arr[i-4:i])) > 0):\n",
    "      drop_indeces.append(i)\n",
    "  return np.delete(arr, drop_indeces, axis=0), np.delete(t, drop_indeces, axis=0), np.delete(dt, drop_indeces, axis=0)\n",
    "\n",
    "def applySavitzkyGolayFilter(arr, window_length, poly_order):\n",
    "  return np.array([savitzkyGolayFilter(arr[:, i], window_length, poly_order) for i in range(arr.shape[1])]).T\n",
    "\n",
    "def savitzkyGolayFilter(data, window_length, poly_order):\n",
    "  return scipy.signal.savgol_filter(data, window_length, poly_order)\n",
    "\n",
    "def applyButterLowpassFilter(arr):\n",
    "  return np.array([butterLowpassFilter(arr[:, i]) for i in range(arr.shape[1])]).T\n",
    "\n",
    "def butterLowpassFilter(data):\n",
    "  nyq = 0.5 * frequency\n",
    "  normal_cutoff = cutoff / nyq\n",
    "  b, a = butter(order, normal_cutoff, btype='lowpass', analog=False)\n",
    "  zi = lfilter_zi(b, a)\n",
    "  y = lfilter(b, a, data, zi=data[0] * zi)[0]\n",
    "  return y\n",
    "\n",
    "def appendHistory(df, data_columns, label_columns, history_length):\n",
    "  state_columns = [col for col in data_columns if \"f\" not in col]\n",
    "  df_state = df[state_columns]\n",
    "  df_state_history = df_state.rename(columns={col: col + \"_t\" for col in state_columns})\n",
    "  for j in range(1, 1 + history_length):\n",
    "    shifted_df = df_state.shift(j)\n",
    "    for k in range(j):\n",
    "      shifted_df.iloc[k] = shifted_df.iloc[j]  # repeat initial elements where shift has left NaNs\n",
    "    col_names = {col: col + \"_t-\" + str(j) for col in list(df.columns)}\n",
    "    shifted_df.rename(columns=col_names, inplace=True)\n",
    "    df_state_history = pd.concat([shifted_df, df_state_history], axis=1)\n",
    "\n",
    "  input_columns = [col for col in data_columns if \"f\" in col]\n",
    "  df_input = df[input_columns]\n",
    "  df_input_history = df_input.rename(columns={col: col + \"_t\" for col in input_columns})\n",
    "  for j in range(1, 1 + history_length):\n",
    "    shifted_df = df_input.shift(j)\n",
    "    for k in range(j):\n",
    "      shifted_df.iloc[k] = shifted_df.iloc[j]  # repeat initial elements where shift has left NaNs\n",
    "    col_names = {col: col + \"_t-\" + str(j) for col in list(df.columns)}\n",
    "    shifted_df.rename(columns=col_names, inplace=True)\n",
    "    df_input_history = pd.concat([shifted_df, df_input_history], axis=1)\n",
    "\n",
    "  df_history = pd.concat([df_state_history, df_input_history, df[label_columns]], axis=1)\n",
    "  return df_history\n",
    "\n",
    "def computeSpline(str, arr, t, steps, cols):\n",
    "  if len(t.shape) == 1:\n",
    "    t = t.reshape((t.shape[0], 1))\n",
    "  splines = {}\n",
    "  for i in range(len(cols)):\n",
    "    splines[str + \"_\" + cols[i]] = scipy.interpolate.CubicSpline(t[:, 0], arr[:, i])(steps, 0)\n",
    "  return splines\n",
    "\n",
    "def nominalModel(data, thrust_coeff, torque_coeff, inertia, mass, arm_length):\n",
    "  q = np.vstack((np.vstack((data[\"q_w\"], data[\"q_x\"])), np.vstack((data[\"q_y\"], data[\"q_z\"])))).T\n",
    "  f = np.vstack((np.vstack((data[\"f_0\"], data[\"f_1\"])), np.vstack((data[\"f_2\"], data[\"f_3\"])))).T\n",
    "  w = np.vstack((np.vstack((data[\"w_x\"], data[\"w_y\"])), data[\"w_z\"])).T\n",
    "\n",
    "  vdot = []\n",
    "  for i in range(q.shape[0]):\n",
    "    thrust = f[i, 0] + f[i, 1] + f[i, 2] + f[i, 3]\n",
    "    quat_norm = q[i, 0] ** 2 + q[i, 1] ** 2 + q[i, 2] ** 2 + q[i, 3] ** 2\n",
    "    vdot.append([\n",
    "      (1. / mass) * thrust * 2. * (q[i, 0] * q[i, 2] + q[i, 1] * q[i, 3]) / quat_norm,\n",
    "      (1. / mass) * thrust * 2. * (q[i, 2] * q[i, 3] - q[i, 0] * q[i, 1]) / quat_norm,\n",
    "      (1. / mass) * thrust * (1. - 2. * q[i, 1] * q[i, 1] - 2. * q[i, 2] * q[i, 2]) / quat_norm - 9.8066\n",
    "    ])\n",
    "\n",
    "  wdot = []\n",
    "  km_kf = torque_coeff / thrust_coeff\n",
    "  for i in range(w.shape[0]):\n",
    "    wdot.append([\n",
    "      (arm_length * (f[i, 0] + f[i, 1] - f[i, 2] - f[i, 3])  + inertia[1] * w[i, 1] * w[i, 2] - inertia[2] * w[i, 1] * w[i, 2]) / inertia[0],\n",
    "      (arm_length * (-f[i, 0] + f[i, 1] + f[i, 2] - f[i, 3]) - inertia[0] * w[i, 0] * w[i, 2] + inertia[2] * w[i, 0] * w[i, 2]) / inertia[1],\n",
    "      (km_kf      * (f[i, 0] - f[i, 1] + f[i, 2] - f[i, 3])  + inertia[0] * w[i, 0] * w[i, 1] - inertia[1] * w[i, 0] * w[i, 1]) / inertia[2]\n",
    "    ])\n",
    "\n",
    "  return np.array(vdot), np.array(wdot)\n",
    "\n",
    "# low pass filter\n",
    "frequency = 100.0\n",
    "cutoff = 5\n",
    "order = 4\n",
    "shift_step = 9\n",
    "\n",
    "def processBag(path):\n",
    "  # quadrotor physics\n",
    "  mass = 0.25\n",
    "  thrust_coeff = 4.37900e-09\n",
    "  torque_coeff = 3.97005e-11\n",
    "  arm_length = 0.076\n",
    "  inertia = np.array([0.000601, 0.000589, 0.001076])\n",
    "\n",
    "  # load dataframes\n",
    "  df_odom = parseBag('/dragonfly17/odom', str(path))\n",
    "  df_imu = parseBag('/dragonfly17/imu', str(path))\n",
    "  df_motor = parseBag('/dragonfly17/motor_rpm', str(path))\n",
    "\n",
    "  # compute time\n",
    "#   t_odom = df_odom.apply(lambda r: rospy.Time(r[\"header.stamp.secs\"], r[\"header.stamp.nsecs\"]).to_sec(), axis=1)\n",
    "#   t_imu = df_imu.apply(lambda r: (r[\"header.stamp.secs\"] + (r[\"header.stamp.nsecs\"] / 1e9)), axis=1)\n",
    "#   t_motor = df_motor.apply(lambda r: rospy.Time(r[\"header.stamp.secs\"], r[\"header.stamp.nsecs\"]).to_sec(), axis=1)\n",
    "\n",
    "  t_odom = df_odom.apply(lambda r: r[\"header.stamp.secs\"] + r[\"header.stamp.nsecs\"] / 1e9, axis=1)\n",
    "  t_imu = df_imu.apply(lambda r: r[\"header.stamp.secs\"] + r[\"header.stamp.nsecs\"] / 1e9, axis=1)\n",
    "  t_motor = df_motor.apply(lambda r: r[\"header.stamp.secs\"] + r[\"header.stamp.nsecs\"] / 1e9, axis=1)\n",
    "\n",
    "  t_odom = t_odom.to_numpy().reshape((len(t_odom), 1))\n",
    "  t_imu = t_imu.to_numpy().reshape((len(t_imu), 1))\n",
    "  t_motor = t_motor.to_numpy().reshape((len(t_motor), 1))\n",
    "  dt_odom = t_odom - shift(t_odom)\n",
    "  dt_imu = t_imu - shift(t_imu)\n",
    "  dt_motor = t_motor - shift(t_motor)\n",
    "  dt_odom[np.isnan(dt_odom)] = 0.\n",
    "  dt_imu[np.isnan(dt_imu)] = 0.\n",
    "  dt_motor[np.isnan(dt_motor)] = 0.\n",
    "\n",
    "  # sampling steps\n",
    "  sampling_bounds = [max(np.min(t_odom), np.min(t_imu), np.min(t_motor)),\n",
    "                     min(np.max(t_odom), np.max(t_imu), np.max(t_motor))]\n",
    "  sampling_bounds[0] = round(sampling_bounds[0] - sampling_bounds[0] % 1. / frequency, 4)\n",
    "  sampling_bounds[1] = round(sampling_bounds[1] - sampling_bounds[1] % 1. / frequency, 4)\n",
    "  sampling_steps = np.arange(sampling_bounds[0], sampling_bounds[1], 1. / frequency)[:-1]\n",
    "\n",
    "  # store all processed data in a dictionary\n",
    "  sampled_data = {\"t\": sampling_steps}\n",
    "\n",
    "  ## position\n",
    "  p = df_odom[[\"pose.pose.position.x\", \"pose.pose.position.y\", \"pose.pose.position.z\"]].to_numpy()\n",
    "  sampled_data.update(computeSpline(\"p\", p, t_odom, sampling_steps, \"xyz\"))\n",
    "\n",
    "  ## orientation\n",
    "  q = df_odom[[\"pose.pose.orientation.w\", \"pose.pose.orientation.x\",\n",
    "               \"pose.pose.orientation.y\", \"pose.pose.orientation.z\"]].to_numpy()\n",
    "  # r = [scipy_rotation.from_quat(q[i, :]).as_matrix() for i in range(q.shape[0])]\n",
    "  q = applyButterLowpassFilter(q)\n",
    "  sampled_data.update(computeSpline(\"q\", q, t_odom, sampling_steps, \"wxyz\"))\n",
    "\n",
    "  ## motor speeds\n",
    "  u = df_motor[[\"rpm_0\", \"rpm_1\", \"rpm_2\", \"rpm_3\"]].to_numpy()\n",
    "  u, t_filt, _ = dropNoise(u, t_motor, dt_motor)\n",
    "  u = applyButterLowpassFilter(u)\n",
    "  sampled_data.update(computeSpline(\"u\", u, t_filt, sampling_steps, \"0123\"))\n",
    "\n",
    "  ## motor thrusts\n",
    "  f = (u ** 2) * thrust_coeff\n",
    "  sampled_data.update(computeSpline(\"f\", f, t_filt, sampling_steps, \"0123\"))\n",
    "\n",
    "  ## linear velocity\n",
    "  v = df_odom[[\"twist.twist.linear.x\", \"twist.twist.linear.y\", \"twist.twist.linear.z\"]].to_numpy()\n",
    "  v, t_filt, dt_filt = dropNoise(v, t_odom, dt_odom)\n",
    "  v = applyButterLowpassFilter(v)\n",
    "  # v = applySavitzkyGolayFilter(v, window_length=101, poly_order=4)\n",
    "  sampled_data.update(computeSpline(\"v\", v, t_filt, sampling_steps, \"xyz\"))\n",
    "\n",
    "  ## angular velocity\n",
    "  # w = df_odom[[\"twist.twist.angular.x\", \"twist.twist.angular.y\", \"twist.twist.angular.z\"]].to_numpy()\n",
    "  w = df_imu[[\"angular_velocity.x\", \"angular_velocity.y\", \"angular_velocity.z\"]].to_numpy()\n",
    "  w = w * np.array([1, -1, -1])\n",
    "  w = applyButterLowpassFilter(w)\n",
    "  # w = applySavitzkyGolayFilter(w, window_length=101, poly_order=4)\n",
    "  sampled_data.update(computeSpline(\"w\", w, t_imu, sampling_steps, \"xyz\"))\n",
    "\n",
    "  ## linear acceleration\n",
    "  vdot = differentiate(v, dt_filt)\n",
    "  # vdot = differentiateFivePointStencil(v, dt_filt)\n",
    "  vdot = applyButterLowpassFilter(vdot)\n",
    "  # vdot = applySavitzkyGolayFilter(vdot, window_length=101, poly_order=4)\n",
    "  sampled_data.update(computeSpline(\"vdot\", vdot, t_filt, sampling_steps, \"xyz\"))\n",
    "\n",
    "  ## angular acceleration\n",
    "  wdot = differentiate(w, dt_imu)\n",
    "  # wdot = differentiateFivePointStencil(w, dt_imu)\n",
    "  wdot = applyButterLowpassFilter(wdot)\n",
    "  # wdot = applySavitzkyGolayFilter(wdot, window_length=101, poly_order=4)\n",
    "  sampled_data.update(computeSpline(\"wdot\", wdot, t_imu, sampling_steps, \"xyz\"))\n",
    "\n",
    "  ## nominal model\n",
    "  vdot_nom, wdot_nom = nominalModel(sampled_data, thrust_coeff, torque_coeff, inertia, mass, arm_length)\n",
    "  sampled_data.update(computeSpline(\"vdot_nom\", vdot_nom, sampled_data[\"t\"], sampling_steps, \"xyz\"))\n",
    "  sampled_data.update(computeSpline(\"wdot_nom\", wdot_nom, sampled_data[\"t\"], sampling_steps, \"xyz\"))\n",
    "\n",
    "  # shift filtered data\n",
    "  shiftFilteredSpline(sampled_data, step=shift_step)\n",
    "\n",
    "  # shift time so that it starts from 0.0\n",
    "  sampled_data[\"t\"] -= sampled_data[\"t\"][0]\n",
    "\n",
    "  return sampled_data\n",
    "\n",
    "def extract_hdf_from_bag(bag_path,save_path):\n",
    "    processed_data = processBag(bag_path)\n",
    "    #remove temporary directory with generated csv files\n",
    "    shutil.rmtree(Path(bag_path).with_suffix(\"\"))\n",
    "\n",
    "    df = pd.concat({k: pd.Series(v) for k, v in processed_data.items()}, axis=1)\n",
    "\n",
    "    file_name = Path(bag_path).stem\n",
    "    with h5py.File(Path(save_path) / (file_name + \".hdf5\"), \"w\") as f:\n",
    "        for col in df.columns:\n",
    "            f.create_dataset(col, data=df[col].values, dtype='f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def dl_quad_pi(\n",
    "        save_path: Path, # directory the files are written to, created if it does not exist\n",
    "        force_download: bool = False, # force download the dataset\n",
    "        remove_download: bool = False # remove downloaded zip/extracted bags afterwards\n",
    ") -> None:\n",
    "    save_path = Path(save_path)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    download_dir = Path(get_tmp_benchmark_directory()) / 'Quadrotor_pi/'\n",
    "    download_dir.mkdir(parents=True, exist_ok=True)\n",
    "    zip_target_path = download_dir / 'bags.zip'\n",
    "    url = 'https://drive.google.com/file/d/1b1PFSBlKTdrlTIurYNpTJWWEx1KIJzuR/view?usp=sharing'\n",
    "\n",
    "    if force_download and zip_target_path.is_file():\n",
    "        os.remove(zip_target_path) # Remove existing file to force re-download\n",
    "\n",
    "    gdown.cached_download(\n",
    "        url, str(zip_target_path), postprocess=gdown.extractall, fuzzy=True\n",
    "    )\n",
    "\n",
    "    for bag_path_str in glob.glob(str(download_dir / \"*.bag\")):\n",
    "        bag_path = Path(bag_path_str)\n",
    "        hdf_dir = save_path / get_parent_dir(bag_path.stem)\n",
    "        hdf_dir.mkdir(parents=True, exist_ok=True)\n",
    "        extract_hdf_from_bag(bag_path, hdf_dir)\n",
    "\n",
    "    if remove_download:\n",
    "        shutil.rmtree(download_dir)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File exists: /Users/daniel/Library/Application Support/nonlinear_benchmarks/Quadrotor_pi/bags.zip\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = idb.get_default_data_root()\n",
    "dl_quad_pi(tmp_dir / 'quad_pi')\n",
    "# quad_pi(tmp_dir / 'quad_pi',force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "quad_pi_u = ['u_0','u_1','u_2','u_3']\n",
    "\n",
    "quad_pi_x_v = ['v_x','v_y','v_z']\n",
    "quad_pi_x_q = ['q_w','q_x','q_y','q_z']\n",
    "quad_pi_x_w = ['w_x','w_y','w_z']\n",
    "quad_pi_x = quad_pi_x_v + quad_pi_x_q + quad_pi_x_w\n",
    "\n",
    "quad_pi_y_vdot = ['vdot_x','vdot_y','vdot_z']\n",
    "quad_pi_y_wdot = ['wdot_x','wdot_y','wdot_z']\n",
    "quad_pi_y = quad_pi_y_vdot + quad_pi_y_wdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "BenchmarkQuadPi_Simulation = idb.BenchmarkSpecSimulation(\n",
    "    name='BenchmarkQuadPi_Simulation', dataset_id='quad_pi',\n",
    "    u_cols=quad_pi_u, y_cols=quad_pi_y, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_quad_pi,\n",
    "    init_window=100\n",
    ")\n",
    "BenchmarkQuadPi_Prediction = idb.BenchmarkSpecPrediction(\n",
    "    name='BenchmarkQuadPi_Prediction', dataset_id='quad_pi',\n",
    "    u_cols=quad_pi_u, y_cols=quad_pi_y, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_quad_pi,\n",
    "    init_window=100, pred_horizon=100,pred_step=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkQuadPi_Simulation, seed: 3951643791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9486249384857373"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkQuadPi_Simulation, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkQuadPi_Prediction, seed: 1289423199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.698025508463279"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkQuadPi_Prediction, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
