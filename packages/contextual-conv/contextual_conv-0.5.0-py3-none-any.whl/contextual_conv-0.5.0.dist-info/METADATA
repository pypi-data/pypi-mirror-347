Metadata-Version: 2.4
Name: contextual-conv
Version: 0.5.0
Summary: PyTorch convolutional layers with global context conditioning
Author-email: Mehdi Abbassi <mehdi.n.abbassi@gmail.com>
License: GPL-3.0-only
Project-URL: Homepage, https://github.com/abbassix/ContextualConv
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: torch; extra == "dev"
Requires-Dist: numpy; extra == "dev"
Dynamic: license-file


# ContextualConv

[![PyPI version](https://img.shields.io/pypi/v/contextual-conv)](https://pypi.org/project/contextual-conv/)
[![CI](https://github.com/abbassix/ContextualConv/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/abbassix/ContextualConv/actions/workflows/test.yml)
[![Docs](https://readthedocs.org/projects/contextualconv/badge/?version=latest)](https://contextualconv.readthedocs.io/en/latest/)
[![Coverage](https://img.shields.io/codecov/c/github/abbassix/ContextualConv/main.svg?style=flat)](https://codecov.io/gh/abbassix/ContextualConv)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

> **ContextualConv** â€“ PyTorch convolutional layers with **global context conditioning**: perâ€‘channel **bias**, **scale**, or **modulated FiLM-style scaling**.

---

## ğŸš€ Quick start

```python
from contextual_conv import ContextualConv2d
import torch

# FiLMâ€‘style (scale + bias)
conv = ContextualConv2d(
    in_channels=16,
    out_channels=32,
    kernel_size=3,
    padding=1,
    context_dim=10,   # size of global vector c
    h_dim=64,         # optional MLP hidden dim
    use_scale=True,   # Î³(c)
    use_bias=True,    # Î²(c)
    scale_mode="film" # or "scale"
)

x = torch.randn(8, 16, 32, 32)  # feature map
c = torch.randn(8, 10)          # context vector

out = conv(x, c)  # shape: (8, 32, 32, 32)
```

### Modes at a glance

| `use_scale` | `use_bias` | `scale_mode` | Behaviour |
|-------------|------------|--------------|-----------|
| `False`     | `True`     | â€“            | **Contextual bias** only |
| `True`      | `False`    | `"scale"`    | **Scale only**: `out * Î³` |
| `True`      | `True`     | `"film"`     | **FiLM**: `out * (1 + Î³) + Î²` |
| `True`      | `True`     | `"scale"`    | **Scale + shift**: `out * Î³ + Î²` |

If *both* flags are `False`, the constructor raises `ValueError`.

---

## ğŸ”§ Key features

* âš™ï¸ **Dropâ€‘in replacement** for `nn.Conv1d` / `nn.Conv2d`  
  â†’ Same arguments + optional context options.
* ğŸ§  **Global vector conditioning** via learnable Î³(c) and/or Î²(c)
* ğŸ”€ **Modulation modes**:
  * `scale_mode="film"`: `out * (1 + Î³)`
  * `scale_mode="scale"`: `out * Î³`
* ğŸª¶ **Lightweight** â€“ one small MLP (or single `Linear`) per layer
* ğŸ§‘â€ğŸ”¬ **FiLM ready** â€“ reproduce Featureâ€‘wise Linear Modulation with two lines
* ğŸ§© **Modular** â€“ combine with any architecture, works on CPU / GPU
* âœ… **Unitâ€‘tested** and documented

---

## ğŸ“¦ Installation

```bash
pip install contextual-conv  # version 0.4.0 on PyPI
```

Or install from source:

```bash
git clone https://github.com/abbassix/ContextualConv.git
cd ContextualConv
pip install -e .[dev]
```

---

## ğŸ“ Context vector details

* Shape: **`(B, context_dim)`**  
  (one global descriptor per sample â€“ class label embedding, latent code, etc.)
* Processed by a **`ContextProcessor`**:
  * `Linear(context_dim, out_dim)` *(biasâ€‘only / scaleâ€‘only)*
  * Small **MLP** if `h_dim` is set.
* Output dims:
  * `out_channels` â†’ bias **or** scale
  * `2 Ã— out_channels` â†’ FiLM (scaleÂ +Â bias)

---

## ğŸ§ª Running tests

Run the full test suite with coverage:

```bash
pytest --cov=contextual_conv --cov-report=term-missing
```

---

## ğŸ“˜ Documentation

Full API reference & tutorials: **<https://contextualconv.readthedocs.io>**

---

## ğŸ¤ Contributing

Bug reports, feature requests, and PRs are welcome! See `CONTRIBUTING.md`.

---

## ğŸ“„ License

GNU GPLv3 â€“ see `LICENSE` file for details.
